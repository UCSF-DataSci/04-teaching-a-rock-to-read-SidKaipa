{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466204de",
   "metadata": {},
   "source": [
    "# The Lazy Book Report\n",
    "\n",
    "Your professor has assigned a book report on \"The Red-Headed League\" by Arthur Conan Doyle. \n",
    "\n",
    "You haven't read the book. And out of stubbornness, you won't.\n",
    "\n",
    "But you *have* learned NLP. Let's use it to answer the professor's questions without reading.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's fetch the text from Project Gutenberg and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a46884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story loaded: 4000 words in 3 sections\n",
      "Section sizes: [1333, 1333, 1334]\n"
     ]
    }
   ],
   "source": [
    "# Fetch and prepare text - RUN THIS CELL FIRST\n",
    "import os\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "url = 'https://www.gutenberg.org/files/1661/1661-0.txt'\n",
    "req = urllib.request.Request(url, headers={'User-Agent': 'Python-urllib'})\n",
    "with urllib.request.urlopen(req, timeout=30) as resp:\n",
    "    text = resp.read().decode('utf-8')\n",
    "\n",
    "# Strip Gutenberg boilerplate\n",
    "text = text.split('*** START OF')[1].split('***')[1]\n",
    "text = text.split('*** END OF')[0]\n",
    "\n",
    "# Extract \"The Red-Headed League\" story (it's the second story in the collection)\n",
    "matches = list(re.finditer(r'THE RED-HEADED LEAGUE', text, re.IGNORECASE))\n",
    "story_start = matches[1].end()\n",
    "story_text = text[story_start:]\n",
    "story_end = re.search(r'\\n\\s*III\\.\\s*\\n', story_text)\n",
    "story_text = story_text[:story_end.start()] if story_end else story_text\n",
    "\n",
    "# Split into 3 sections by word count\n",
    "words = story_text.split()[:4000]\n",
    "section_size = len(words) // 3\n",
    "sections = [\n",
    "    ' '.join(words[:section_size]),\n",
    "    ' '.join(words[section_size:2*section_size]),\n",
    "    ' '.join(words[2*section_size:])\n",
    "]\n",
    "\n",
    "print(f\"Story loaded: {len(words)} words in {len(sections)} sections\")\n",
    "print(f\"Section sizes: {[len(s.split()) for s in sections]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e757a",
   "metadata": {},
   "source": [
    "## Professor's Questions\n",
    "\n",
    "Your professor wants you to answer 5 questions about the story. Let's use NLP to find the answers.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1: Writing Style\n",
    "\n",
    "> \"This text is from the 1890s. What makes it different from modern writing?\"\n",
    "\n",
    "**NLP Method:** Use preprocessing to compute text statistics. Tokenize the text and calculate:\n",
    "- Vocabulary richness (unique words / total words)\n",
    "- Average sentence length\n",
    "- Average word length\n",
    "\n",
    "**Hint:** Formal, literary writing typically shows higher vocabulary richness and longer sentences than modern casual text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1710e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/roopadilip/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Richness: 0.08\n",
      "Avg Sentence Length: 24.07 words\n",
      "Avg Word Length: 3.92 letters\n"
     ]
    }
   ],
   "source": [
    "# Your code here: compute text statistics\n",
    "# You'll need: import string, import re\n",
    "# - Tokenize: remove punctuation, lowercase\n",
    "# - Sentences: split on sentence-ending punctuation\n",
    "# Calculate vocab_richness, avg_sentence_length, avg_word_length\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "clean_text = story_text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "words_in_story = nltk.word_tokenize(clean_text)\n",
    "sentence_in_story = nltk.sent_tokenize(story_text)\n",
    "\n",
    "vocab_richness = len(set(words_in_story))/len(words_in_story)\n",
    "\n",
    "avg_sentence_length = len(words_in_story)/len(sentence_in_story)\n",
    "\n",
    "sum_word = 0\n",
    "for w in words_in_story:\n",
    "    sum_word += len(w)\n",
    "avg_word_length = sum_word/len(words_in_story)\n",
    "\n",
    "print(f\"Vocab Richness: {vocab_richness:.2f}\")\n",
    "print(f\"Avg Sentence Length: {avg_sentence_length:.2f} words\")\n",
    "print(f\"Avg Word Length: {avg_word_length:.2f} letters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5545405",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2: Main Characters\n",
    "\n",
    "> \"Who are the main characters in this story?\"\n",
    "\n",
    "**NLP Method:** Use Named Entity Recognition (NER) to extract PERSON entities.\n",
    "\n",
    "**Hint:** Use spaCy's `en_core_web_sm` model. Process the text and filter entities where `ent.label_ == 'PERSON'`. Count how often each name appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "332a59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: extract PERSON entities using spaCy NER\n",
    "# You'll need: import spacy, nlp = spacy.load(\"en_core_web_sm\")\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "t = nlp(story_text)\n",
    "# When done, save your findings:\n",
    "# with open(\"output/characters.txt\", \"w\") as f:\n",
    "#     for name in your_character_list:\n",
    "#         f.write(f\"{name}\\n\")\n",
    "\n",
    "name_map = {\n",
    "    \"Sherlock\": \"Sherlock Holmes\",\n",
    "    \"Holmes\": \"Sherlock Holmes\",\n",
    "    \"John\": \"John Watson\",\n",
    "    \"Watson\": \"John Watson\",\n",
    "    \"Jabez\": \"Jabez Wilson\",\n",
    "    \"Wilson\": \"Jabez Wilson\",\n",
    "    \"Mary\": \"Mary Sutherland\",\n",
    "    \"Sutherland\": \"Mary Sutherland\",\n",
    "\n",
    "}\n",
    "characters = {}\n",
    "for ent in t.ents:\n",
    "    if ent.label_ == \"PERSON\":\n",
    "        original_name = ent.text\n",
    "        proper_name = name_map.get(original_name,original_name)\n",
    "        if proper_name not in characters:\n",
    "            characters[proper_name] = 1\n",
    "        else:\n",
    "            characters[proper_name] += 1\n",
    "\n",
    "sorted_characters = sorted(characters.items(), key=lambda x: x[1], reverse=True)\n",
    "with open(\"output/characters.txt\", \"w\") as f:\n",
    "    for name,count in sorted_characters:\n",
    "        f.write(f\"{name}: {count}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732e661",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 3: Story Locations\n",
    "\n",
    "> \"Where does the story take place?\"\n",
    "\n",
    "**NLP Method:** Use Named Entity Recognition (NER) to extract location entities (GPE and LOC).\n",
    "\n",
    "**Hint:** Filter entities where `ent.label_` is 'GPE' (geopolitical entity) or 'LOC' (location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3f8f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('London', 33), ('England', 18), ('America', 10), ('France', 6), ('Eyford', 6), ('China', 5), ('India', 4), ('Boscombe Valley', 3), ('Florida', 3), ('Europe', 3), ('Savannah', 3), ('California', 3), ('Streatham', 3), ('U.S.A.', 2), ('Encyclopædia Britannica', 2), ('Underground', 2), ('Scotland', 2), ('Scarlet', 2), ('Australia', 2), ('Victoria', 2), ('Bristol', 2), ('Ballarat', 2), ('Major Prendergast', 2), ('Horsham', 2), ('Georgia', 2), ('South', 2), ('Atlantic', 2), ('morocco', 2), ('Covent Garden', 2), ('Berkshire', 2), ('San Francisco', 2), ('Frisco', 2), ('Pa.', 2), ('Holmes', 2), ('Philadelphia', 2), ('Rucastle', 2), ('Lebanon', 1), ('Pennsylvania', 1), ('Londoners', 1), ('Abbots', 1), ('Strand', 1), ('west.', 1), ('the City and Suburban Bank', 1), ('Kensington', 1), ('Oxford', 1), ('Cornwall', 1), ('Holland', 1), ('Marseilles', 1), ('Auckland', 1), ('New Zealand', 1), ('Leadenhall\\r\\nStreet', 1), ('the St. Pancras\\r\\nHotel', 1), ('Andover', 1), ('The Hague', 1), ('Horace', 1), ('Afghanistan', 1), ('Hatherley', 1), ('the Boscombe Valley', 1), ('n’t', 1), ('Rotterdam', 1), ('Melbourne', 1), ('Uffa', 1), ('Jackson', 1), ('Sussex', 1), ('States', 1), ('North', 1), ('East London', 1), ('Dundee', 1), ('Tennessee', 1), ('Louisiana', 1), ('Carolinas', 1), ('United States', 1), ('the\\r\\nUnion', 1), ('Texas', 1), ('D.D.', 1), ('Capital', 1), ('Middlesex', 1), ('Neville', 1), ('Chesterfield', 1), ('the\\r\\nCity', 1), ('Swandam\\r\\nLane', 1), ('St. James’s Gazette', 1), ('the Amoy River', 1), ('crisply', 1), ('Holborn', 1), ('Brixton', 1), ('geese', 1), ('Pentonville', 1), ('Kilburn', 1), ('Crewe', 1), ('Reading', 1), ('lodgings', 1), ('Greenwich', 1), ('Esq', 1), ('Cal.', 1), ('Great Britain', 1), ('Petersfield', 1), ('Pacific', 1), ('Hyde Park', 1), ('Aberdeen', 1), ('Munich', 1), ('8_s', 1), ('the Arabian Nights', 1), ('Rockies', 1), ('Montana', 1), ('Arizona', 1), ('New Mexico', 1), ('Paris', 1), ('the City of London', 1), ('the West End', 1), ('Wooden', 1), ('china', 1), ('Nova Scotia', 1), ('Hampshire', 1), ('Southampton', 1), ('Southerton', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here: extract GPE and LOC entities using spaCy NER\n",
    "\n",
    "# When done, save your findings:\n",
    "# with open(\"output/locations.txt\", \"w\") as f:\n",
    "#     for place in your_locations_list:\n",
    "#         f.write(f\"{place}\\n\")\n",
    "\n",
    "locations = {}\n",
    "for ent in t.ents:\n",
    "    if ent.label_ in[\"GPE\",\"LOC\"]:\n",
    "        place = ent.text\n",
    "        if place not in locations:\n",
    "            locations[place] = 1\n",
    "        else:\n",
    "            locations[place] += 1\n",
    "sorted_locations = sorted(locations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(sorted_locations)\n",
    "with open(\"output/locations.txt\", \"w\") as f:\n",
    "   for loc,count in sorted_locations:\n",
    "       f.write(f\"{loc}: {count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b228d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 4: Wilson's Business\n",
    "\n",
    "> \"What is Wilson's business?\"\n",
    "\n",
    "**NLP Method:** Use TF-IDF similarity to find which section discusses Wilson's business.\n",
    "\n",
    "**Hint:** Create a TF-IDF vectorizer, fit it on the 3 sections, then transform your query using the same vectorizer (`.transform()`, not `.fit_transform()` - you want to use the vocabulary learned from the sections). Find which section has the highest cosine similarity and read it to find the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24f7fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.18361726647829435\n",
      "I had called upon my friend, Mr. Sherlock Holmes, one day in the autumn of last year and found him in deep conversation with a very stout, florid-faced, elderly gentleman with fiery red hair. With an apology for my intrusion, I was about to withdraw when Holmes pulled me abruptly into the room and closed the door behind me. “You could not possibly have come at a better time, my dear Watson,” he said cordially. “I was afraid that you were engaged.” “So I am. Very much so.” “Then I can wait in the next room.” “Not at all. This gentleman, Mr. Wilson, has been my partner and helper in many of my most successful cases, and I have no doubt that he will be of the utmost use to me in yours also.” The stout gentleman half rose from his chair and gave a bob of greeting, with a quick little questioning glance from his small fat-encircled eyes. “Try the settee,” said Holmes, relapsing into his armchair and putting his fingertips together, as was his custom when in judicial moods. “I know, my dear Watson, that you share my love of all that is bizarre and outside the conventions and humdrum routine of everyday life. You have shown your relish for it by the enthusiasm which has prompted you to chronicle, and, if you will excuse my saying so, somewhat to embellish so many of my own little adventures.” “Your cases have indeed been of the greatest interest to me,” I observed. “You will remember that I remarked the other day, just before we went into the very simple problem presented by Miss Mary Sutherland, that for strange effects and extraordinary combinations we must go to life itself, which is always far more daring than any effort of the imagination.” “A proposition which I took the liberty of doubting.” “You did, Doctor, but none the less you must come round to my view, for otherwise I shall keep on piling fact upon fact on you until your reason breaks down under them and acknowledges me to be right. Now, Mr. Jabez Wilson here has been good enough to call upon me this morning, and to begin a narrative which promises to be one of the most singular which I have listened to for some time. You have heard me remark that the strangest and most unique things are very often connected not with the larger but with the smaller crimes, and occasionally, indeed, where there is room for doubt whether any positive crime has been committed. As far as I have heard, it is impossible for me to say whether the present case is an instance of crime or not, but the course of events is certainly among the most singular that I have ever listened to. Perhaps, Mr. Wilson, you would have the great kindness to recommence your narrative. I ask you not merely because my friend Dr. Watson has not heard the opening part but also because the peculiar nature of the story makes me anxious to have every possible detail from your lips. As a rule, when I have heard some slight indication of the course of events, I am able to guide myself by the thousands of other similar cases which occur to my memory. In the present instance I am forced to admit that the facts are, to the best of my belief, unique.” The portly client puffed out his chest with an appearance of some little pride and pulled a dirty and wrinkled newspaper from the inside pocket of his greatcoat. As he glanced down the advertisement column, with his head thrust forward and the paper flattened out upon his knee, I took a good look at the man and endeavoured, after the fashion of my companion, to read the indications which might be presented by his dress or appearance. I did not gain very much, however, by my inspection. Our visitor bore every mark of being an average commonplace British tradesman, obese, pompous, and slow. He wore rather baggy grey shepherd’s check trousers, a not over-clean black frock-coat, unbuttoned in the front, and a drab waistcoat with a heavy brassy Albert chain, and a square pierced bit of metal dangling down as an ornament. A frayed top-hat and a faded brown overcoat with a wrinkled velvet collar lay upon a chair beside him. Altogether, look as I would, there was nothing remarkable about the man save his blazing red head, and the expression of extreme chagrin and discontent upon his features. Sherlock Holmes’ quick eye took in my occupation, and he shook his head with a smile as he noticed my questioning glances. “Beyond the obvious facts that he has at some time done manual labour, that he takes snuff, that he is a Freemason, that he has been in China, and that he has done a considerable amount of writing lately, I can deduce nothing else.” Mr. Jabez Wilson started up in his chair, with his forefinger upon the paper, but his eyes upon my companion. “How, in the name of good-fortune, did you know all that, Mr. Holmes?” he asked. “How did you know, for example, that I did manual labour. It’s as true as gospel, for I began as a ship’s carpenter.” “Your hands, my dear sir. Your right hand is quite a size larger than your left. You have worked with it, and the muscles are more developed.” “Well, the snuff, then, and the Freemasonry?” “I won’t insult your intelligence by telling you how I read that, especially as, rather against the strict rules of your order, you use an arc-and-compass breastpin.” “Ah, of course, I forgot that. But the writing?” “What else can be indicated by that right cuff so very shiny for five inches, and the left one with the smooth patch near the elbow where you rest it upon the desk?” “Well, but China?” “The fish that you have tattooed immediately above your right wrist could only have been done in China. I have made a small study of tattoo marks and have even contributed to the literature of the subject. That trick of staining the fishes’ scales of a delicate pink is quite peculiar to China. When, in addition, I see a Chinese coin hanging from your watch-chain, the matter becomes even more simple.” Mr. Jabez Wilson laughed heavily. “Well, I never!” said he. “I thought at first that you had done something clever, but I see that there was nothing in it after all.” “I begin to think, Watson,” said Holmes, “that I make a mistake in explaining. ‘_Omne ignotum pro magnifico_,’ you know, and my poor little reputation, such as it is, will suffer shipwreck if I am so candid. Can you not find the advertisement, Mr. Wilson?” “Yes, I have got it now,” he answered with his thick red finger planted halfway down the column. “Here it is. This is what began it all. You just read it for yourself, sir.” I took the paper from him and read as follows: “TO THE RED-HEADED LEAGUE: On account of the bequest of the late Ezekiah Hopkins, of Lebanon, Pennsylvania, U.S.A., there is now another vacancy open which entitles a member of the League to a salary of £ 4 a week for purely nominal services. All red-headed men who are sound in body and mind and above the age of twenty-one years, are eligible. Apply in person on Monday, at eleven o’clock, to Duncan Ross, at the offices of the League, 7 Pope’s Court, Fleet Street.” “What on earth does this mean?” I ejaculated after I had twice read over the extraordinary announcement. Holmes chuckled and wriggled in his chair, as was his habit when in high spirits. “It is a little off the beaten track, isn’t it?” said he. “And now, Mr. Wilson, off you go at scratch and tell us all about yourself, your household, and the effect which this advertisement had upon\n"
     ]
    }
   ],
   "source": [
    "# Your code here: use TF-IDF similarity to find the relevant section\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query = [\"What is Wilson's business?\"]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "result = vectorizer.fit_transform(sections)\n",
    "vector = vectorizer.transform(query)\n",
    "ret = cosine_similarity(vector, result).flatten()\n",
    "\n",
    "best_index = ret.argmax()\n",
    "best_score = ret[best_index]\n",
    "\n",
    "print(best_index)\n",
    "print(best_score)\n",
    "\n",
    "print(sections[0])\n",
    "\n",
    "with open(\"output/business.txt\", \"w\") as f:\n",
    "    f.write(\"Wilson's business is: Freemasonry\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85452bf1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 5: Wilson's Work Routine\n",
    "\n",
    "> \"What is Wilson's daily work routine for the League?\"\n",
    "\n",
    "**NLP Method:** Use TF-IDF similarity to find which section discusses Wilson's work routine.\n",
    "\n",
    "**Hint:** Similar to Question 4 - use TF-IDF to find the section that best matches your query about work routine. The answer includes what Wilson had to do and what eventually happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ddea14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.13064694976267216\n"
     ]
    }
   ],
   "source": [
    "# Your code here: use TF-IDF similarity to find the relevant section\n",
    "query = [\"What is Wilson's daily work routine for the League?\"]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "result = vectorizer.fit_transform(sections)\n",
    "vector = vectorizer.transform(query)\n",
    "ret = cosine_similarity(vector, result).flatten()\n",
    "\n",
    "best_index = ret.argmax()\n",
    "best_score = ret[best_index]\n",
    "\n",
    "print(best_index)\n",
    "print(best_score)\n",
    "\n",
    "\n",
    "with open(\"output/routine.txt\", \"w\") as f:\n",
    "    f.write(\"Wilson's work routine: He works at his pawnbroker's business, along with his two assistants. He was asked to work from 10 to 2. He would have to be in the office or building the whole time. He needs to copy out the Encyclopedia Britannica\\n\")\n",
    "    f.write(\"What happened: He went to work one day and saw a sign that said THE RED_HEADED LEAGUE IS DISSOLVED\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
